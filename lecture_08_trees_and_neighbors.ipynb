{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cedb406",
   "metadata": {},
   "source": [
    "You can follow along and play with this notebook by clicking the badge below\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/COGS118A/demo_notebooks/blob/main/lecture_08_trees_and_neighbors.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50233350",
   "metadata": {},
   "source": [
    "# Trees\n",
    "\n",
    "### Psuedo-code for a decision tree algorithm\n",
    "\n",
    "You don't need this at all.  This is just a review of the idea that was in the slides :)\n",
    "\n",
    "```python\n",
    "def build_tree(S):\n",
    "    # inputs: dataset S\n",
    "    # outputs: a (sub)tree \n",
    "    if stop_criteria(S): # typically S is pure OR len(S) < some value\n",
    "        return leaf_node(S)\n",
    "    else:\n",
    "        # typically optimal_test() picks a \n",
    "        # test `t_star` (e.g., a feature and a decision threshold)\n",
    "        # that creates `partitions` of S such that\n",
    "        # those partitions maximize an information metric\n",
    "        # i.e., each partition is mostly just a single class\n",
    "        t_star, partitions = optimal_test(S)\n",
    "        \n",
    "        children=[]\n",
    "        for child_S in partitions:\n",
    "            children.append( build_tree(child_S) )\n",
    "        return (t_star + children)\n",
    "```        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d1ed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two useful data viz libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# setup plotting in a notebook in a reasonable way\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "# default figure aesthetics I'll be using, \n",
    "# there are other choices, see seaborn docs\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a164598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get some ðŸ§ data to work with\n",
    "penguins = sns.load_dataset(\"penguins\").dropna()\n",
    "penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce4d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for functions that return a graphics handle\n",
    "# putting a ; afterwards supressed the echo\n",
    "# of the handle to the screen when its the last line\n",
    "# of a cell\n",
    "sns.pairplot(penguins, hue='species');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e00ad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# here's our raw data\n",
    "X = penguins[['bill_length_mm', 'bill_depth_mm', \n",
    "                  'flipper_length_mm', 'body_mass_g']] #, 'sex']]\n",
    "y = penguins['species']\n",
    "\n",
    "# make a train test split with params\n",
    "# test_size=0.33, random_state=42\n",
    "# see sklearn docs!\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d677c3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models we will use\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# here's our model!  look at the docs for options!!\n",
    "# right now we are going to use the defaults.\n",
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25788bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit it to training data!\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError\n",
    "\n",
    "# how good will we do on training set error and test set error?\n",
    "yhat_train = model.predict(X_train)\n",
    "yhat_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f62a000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "acc_train = accuracy_score(y_train, yhat_train)\n",
    "\n",
    "# calculate the test set error\n",
    "acc_test = raise NotImplementedError # YOUR CODE HERE\n",
    "\n",
    "print(f'training set accuracy (n={y_train.shape[0]}): {acc_train:4.3f}')\n",
    "print(f'test set accuracy (n={y_test.shape[0]}): {acc_test:4.3f}')\n",
    "print()\n",
    "print('classificiation report on test set performance')\n",
    "print(classification_report(y_test, yhat_test))\n",
    "print()\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, yhat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aeb376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# great!  so what does our decision tree look like?\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# we need a bigger figure than normal for this plot\n",
    "fig, axes = plt.subplots(figsize=(20,20))\n",
    "\n",
    "plot_tree(model, \n",
    "          feature_names=X_train.columns, \n",
    "          class_names=y_train.drop_duplicates().to_list(),\n",
    "          ax=axes);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e61430",
   "metadata": {},
   "source": [
    "Hmmm.  What do you think these feature_importances below are?  Do the numbers match up to anything related to the tree plot above? Hint: they do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6f01dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_names_in_, model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcd1aca",
   "metadata": {},
   "source": [
    "One thing I was wondering, is it possible to increase the accuracy of the predictions by including sex.  A bit of domain knowledge is helpful here... many species have different sized males and females, and you could easily see that impacting prediction accuracy, where males of smaller species might have measurements similar to females of larger species, causing misclassification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861f0b71",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# make a combo category\n",
    "penguins['species_x_sex'] = penguins['species']+', '+penguins['sex']\n",
    "\n",
    "# this makes color sequence light/dark of the same color\n",
    "# to encode sex for a given species, see seaborn docs\n",
    "with sns.color_palette(\"Paired\"):\n",
    "\n",
    "    # pariplot shows all pairs of real valued variables\n",
    "    sns.pairplot(penguins, hue='species_x_sex', \n",
    "                 hue_order=[ # forces the right order of colors \n",
    "                    'Adelie, Male', 'Adelie, Female',\n",
    "                    'Chinstrap, Male', 'Chinstrap, Female',\n",
    "                    'Gentoo, Male', 'Gentoo, Female']\n",
    "                );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e355e58e",
   "metadata": {},
   "source": [
    "Yep, it sure looks like there is indeed a systematic sex based difference in size across all 3 species.  so lets do it again, this time we will try to improve our classification accuracy by including sex as a feature.\n",
    "\n",
    "Now one thing... sex is a categorical feature, and so it needs transformation. And while its a binary feature in this dataset, we will just go ahead and one-hot encode it for safety.  In fact, while some sklearn algorithms will handle categorical inputs with ease, decision tree classifier is one of the ones that requires us to one-hot a categorical feature before it will work right.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa56e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# here's our raw data, this time include sex!\n",
    "X = penguins[['bill_length_mm', 'bill_depth_mm', \n",
    "                  'flipper_length_mm', 'body_mass_g', 'sex']]\n",
    "y = penguins['species']\n",
    "\n",
    "# here's our training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04824d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# transformers\n",
    "onehot = OneHotEncoder() # use me for categorical data\n",
    "scaler = StandardScaler() # for some algos, you need me for numerical data\n",
    "                          # for other algos, you don't need it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a136add9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whenever we do any kind of preprocessing \n",
    "# (e.g. transformation or normalization)\n",
    "# to our data it is CRITICAL to fit the preprocessor on training data\n",
    "# NOT all the data.  If you fit all the data then you are leaking\n",
    "# information from the test set into training set, and therefore\n",
    "# you are allowing overfitting\n",
    "\n",
    "onehot.fit( X_train[['sex']] )\n",
    "\n",
    "# the to_frame() thing is only necessary becuase onehot expects a\n",
    "# 2d array, and a single column is a 1d array.  if we have multiple\n",
    "# columns to onehot we wouldn't need to_frame() and it wouldn't \n",
    "# exist anyway as it would already be a 2d dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c2fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new one hot encoded gender categories to datasets\n",
    "# ends up as a numpy sparse matrix, so we need to densify it\n",
    "# to assign it back into the dataframe\n",
    "X_train.loc[:, onehot.categories_[0]] = onehot.transform(X_train[['sex']]).todense()\n",
    "X_test.loc[:, onehot.categories_[0]] = onehot.transform(X_test[['sex']]).todense()\n",
    "\n",
    "# drop the old text label category \"sex\"\n",
    "X_train.drop('sex', axis='columns', inplace=True)\n",
    "X_test.drop('sex', axis='columns', inplace=True)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b6f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train);\n",
    "\n",
    "yhat_train = model.predict(X_train)\n",
    "yhat_test = model.predict(X_test)\n",
    "\n",
    "acc_train = accuracy_score(y_train, yhat_train)\n",
    "acc_test = accuracy_score(y_test, yhat_test)\n",
    "\n",
    "print(f'training set accuracy (n={y_train.shape[0]}): {acc_train:4.3f}')\n",
    "print(f'test set accuracy (n={y_test.shape[0]}): {acc_test:4.3f}')\n",
    "print()\n",
    "print('classificiation report on test set performance')\n",
    "print(classification_report(y_test, yhat_test))\n",
    "print()\n",
    "\n",
    "# use this `with` to avoid ugly gridlines in the confusion matrix plot\n",
    "# that an earlier seaborn style statement would have put there\n",
    "# this with is not necessary if you havaen't been using seaborn above\n",
    "with sns.axes_style('white'):\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, yhat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f638acb",
   "metadata": {},
   "source": [
    "So by using a one-hot encoded sex feature we gained 4% accuracy (going from 95% w/o it to 99% w/ it).  In particular without a sex feature, 5 Chinstrap and Adelie penguins were confused with other. With that feature just a single penguin was misclassified. \n",
    "\n",
    "Next up, try to apply a k-NN (lets use k=7) to this data.  Sklearn docs are your best friend.  The main thing you will need is a new `model` but lots of the rest of it can stay the same (i.e. you can copy/paste some of the cells above).\n",
    "\n",
    "Let me suggest to you that if you want to do the best possible performance, then you will need to use the standard scalar transformer on the measurement variables (aka. z-score aka standardize the variables). This is because body mass is a few orders of magnitude bigger than other measurements.  \n",
    "\n",
    "And besides trying to work out how to do this in sklearn, I'm going to pose you the following questions as well:\n",
    "1. Why must we scaler() the measurement data for kNN to get it's best performance?\n",
    "1. Why is it not necessary to scaler() the measurement data for a decision tree?\n",
    "1. Run it both with and without the scaler().  What performance difference do you get on test set accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e76e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import ???\n",
    "\n",
    "# YOUR CODE HERE\n",
    "model= raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c288bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's our raw data, this time include sex!\n",
    "X = penguins[['bill_length_mm', 'bill_depth_mm', \n",
    "                  'flipper_length_mm', 'body_mass_g', 'sex']]\n",
    "y = penguins['species']\n",
    "\n",
    "# here's our training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d966e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_numerical = X_train.drop('sex',axis='columns')\n",
    "X_test_numerical = X_test.drop('sex',axis='columns')\n",
    "scaler.fit(X_train_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1f3036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new one hot encoded gender categories to datasets\n",
    "# ends up as a numpy sparse matrix, so we need to densify it\n",
    "# to assign it back into the dataframe\n",
    "X_train.loc[:, onehot.categories_[0]] = onehot.transform(X_train[['sex']]).todense()\n",
    "X_test.loc[:, onehot.categories_[0]] = onehot.transform(X_test[['sex']]).todense()\n",
    "\n",
    "# drop the old text label category \"sex\"\n",
    "X_train.drop('sex', axis='columns', inplace=True)\n",
    "X_test.drop('sex', axis='columns', inplace=True)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089a5481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new scaler transformed version of the data\n",
    "X_train.loc[:, scaler.feature_names_in_] = scaler.transform(X_train_numerical)\n",
    "X_test.loc[:, scaler.feature_names_in_] = scaler.transform(X_test_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9a4127",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)\n",
    "\n",
    "yhat_train = model.predict(X_train)\n",
    "yhat_test = model.predict(X_test)\n",
    "\n",
    "acc_train = accuracy_score(y_train, yhat_train)\n",
    "acc_test = accuracy_score(y_test, yhat_test)\n",
    "\n",
    "print(f'training set accuracy (n={y_train.shape[0]}): {acc_train:4.3f}')\n",
    "print(f'test set accuracy (n={y_test.shape[0]}): {acc_test:4.3f}')\n",
    "print()\n",
    "print('classificiation report on test set performance')\n",
    "print(classification_report(y_test, yhat_test))\n",
    "print()\n",
    "\n",
    "# use this `with` to avoid ugly gridlines in the confusion matrix plot\n",
    "# that an earlier seaborn style statement would have put there\n",
    "# this with is not necessary if you havaen't been using seaborn above\n",
    "with sns.axes_style('white'):\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, yhat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fdc80f",
   "metadata": {},
   "source": [
    "Now let's compare the above result to one where we don't standardize the variables!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17bdaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's our raw data, this time include sex!\n",
    "X = penguins[['bill_length_mm', 'bill_depth_mm', \n",
    "                  'flipper_length_mm', 'body_mass_g', 'sex']]\n",
    "y = penguins['species']\n",
    "\n",
    "# here's our training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75399112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add one hot encoded gender categories to datasets\n",
    "# BUT DONT add scaler normalized data this time!\n",
    "# feel free to copy paste from previous cells\n",
    "\n",
    "raise NotImplementedError\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3b29c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)\n",
    "\n",
    "yhat_train = model.predict(X_train)\n",
    "yhat_test = model.predict(X_test)\n",
    "\n",
    "acc_train = accuracy_score(y_train, yhat_train)\n",
    "acc_test = accuracy_score(y_test, yhat_test)\n",
    "\n",
    "print(f'training set accuracy (n={y_train.shape[0]}): {acc_train:4.3f}')\n",
    "print(f'test set accuracy (n={y_test.shape[0]}): {acc_test:4.3f}')\n",
    "print()\n",
    "print('classificiation report on test set performance')\n",
    "print(classification_report(y_test, yhat_test))\n",
    "print()\n",
    "\n",
    "# use this `with` to avoid ugly gridlines in the confusion matrix plot\n",
    "# that an earlier seaborn style statement would have put there\n",
    "# this with is not necessary if you havaen't been using seaborn above\n",
    "with sns.axes_style('white'):\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, yhat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e1912e",
   "metadata": {},
   "source": [
    "Look at that!  If you did the same thing I did, you'll end up with 81.8% accuracy without standardizing the numeric variables vs 99.1% accuracy when you did.  That's a substantial change! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa304a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
